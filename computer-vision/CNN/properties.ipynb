{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import cv2 as cv\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Properties of CNN Architecture**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Key Operations\n",
    "\n",
    "#### Convolution\n",
    "\n",
    "1. **Local Receptive Field**: Small portions of the image are convolved with the filter, which is advantageous for capturing local features.\n",
    "2. **Parameter Sharing**: A single set of weights is employed across the entire image, reducing the model's training parameters significantly.\n",
    "\n",
    "#### Pooling\n",
    "\n",
    "1. **Downsampling**: This process compresses the spatial data, making the model robust to variations in scale and orientation.\n",
    "2. **Invariance**: By taking, for instance, the average or maximum pixel intensity in a pooling region, pooling layers display invariance toward small translations.\n",
    "\n",
    "### Feature Hierarchy\n",
    "\n",
    "Each convolutional layer, in essence, stacks its learned features from preceding layers. Early layers are adept at **edge detection**, while deeper layers can interpret these edges as **shapes** or even **complex objects**.\n",
    "\n",
    "### Global Receptive Field\n",
    "\n",
    "With every subsequent convolutional layer, the receptive field—the portion of the input image influencing a neuron's output—expands. This expansion enables the network to discern global relationships from intricate local features.\n",
    "\n",
    "### Regularization & Overfitting\n",
    "\n",
    "CNNs inherently offer **overfitting** avoidance through techniques like pooling and, more importantly, data augmentation, thereby enhancing their real-world adaptability. Moreover, dropout and weight decay are deployable regularizers to curb overfitting, particularly in tasks with limited datasets.\n",
    "\n",
    "### Automated Feature Hierarchy Construction\n",
    "\n",
    "CNNs distinctly differ from traditional computer vision methods that require manual feature engineering. CNNs automate this process, a characteristic vital for intricate visual tasks like **object recognition**.\n",
    "\n",
    "### Real-Time Applications\n",
    "\n",
    "CNNs undergird a profusion of practical implementations ranging from predictive policing with video data to hazard detection in autonomous vehicles. Their efficacy in these real-time scenarios is primarily due to their architecture's efficiency at processing visual information.\n",
    "<br>\n",
    "\n",
    "## 7. What's the significance of _depth perception_ in computer vision applications?\n",
    "\n",
    "**Depth perception** is crucial in various computer vision tasks, improving localization precision, object recognition, and 3D reconstruction.\n",
    "\n",
    "### Core Functions Enabled by Depth Perception\n",
    "\n",
    "#### Segmentation\n",
    "\n",
    "Depth assists in separating foreground objects from the background, crucial in immersive multimedia, robotics, and precision motion detection.\n",
    "\n",
    "#### Object Recognition\n",
    "\n",
    "Incorporating depth enhances the precision of object recognition, especially in cluttered scenes, by offering valuable spatial context.\n",
    "\n",
    "#### 3D Scene Understanding\n",
    "\n",
    "Depth data enables the accurate arrangement and orientation of objects within a scene.\n",
    "\n",
    "#### Image Enhancement\n",
    "\n",
    "Computing depth can lead to image enhancements such as depth-based filtering, super-resolution, and scene orientation corrections.\n",
    "\n",
    "#### Human-Machine Interaction\n",
    "\n",
    "Understanding depth leads to more user-friendly interfaces, especially in augmented reality and human-computer interaction applications.\n",
    "\n",
    "#### Visual Effects\n",
    "\n",
    "Depth contributes to realistic rendering of virtual objects in live-action scenes. Its role in producing immersive 3D experiences in movies, games, and virtual reality is undeniable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
